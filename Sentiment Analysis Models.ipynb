{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3846bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\ziyuxiong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ziyuxiong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ziyuxiong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ziyuxiong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c334f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5aa011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\ziyuxiong\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ziyuxiong\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ziyuxiong\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ziyuxiong\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ziyuxiong\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.2.2)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/126.0 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 20.5/126.0 kB 330.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  122.9/126.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.0/126.0 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5292228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review real_sentiment\n",
      "0   Had not flown EasyJet for over a year because...       negative\n",
      "1     Given the basic fare cost with no hold bagg...       negative\n",
      "2   My EasyJet flights from Oporto to Ajaccio wer...       positive\n",
      "3  ? ?EasyJet are scammers. We were never informe...       negative\n",
      "4    I have been travelling for 5 years, between ...       negative\n"
     ]
    }
   ],
   "source": [
    "# Try different encodings to read the CSV file\n",
    "# Read easyJet Test Data\n",
    "try:\n",
    "    data = pd.read_csv('easyJet_test.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv('easyJet_test.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few lines of data to ensure that the data is read correctly.\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d677e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review real_sentiment\n",
      "0   If you can¡¯t fly First Class don¡¯t fly Brit...       negative\n",
      "1     Singapore to Heathrow. Business class on an...       negative\n",
      "2     I reported my damaged/ruined suitcase 5 wee...       negative\n",
      "3  ? ?On March 1st, I flew from Berlin to S?o Pau...       negative\n",
      "4   The WORST customer experience! British Airway...       negative\n"
     ]
    }
   ],
   "source": [
    "# Try different encodings to read the CSV file\n",
    "# Read British Airways Test Data\n",
    "try:\n",
    "    data_2 = pd.read_csv('british_test.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    data_2 = pd.read_csv('british_test.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few lines of data to ensure that the data is read correctly.\n",
    "print(data_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44086713",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define VADER sentiment classification function\n",
    "def vader_sentiment(review):\n",
    "    sentiment_score = analyzer.polarity_scores(review)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73074692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 0.745\n",
      "VADER Precision: 0.6956657190239279\n",
      "VADER Recall: 0.745\n",
      "VADER F1 Score: 0.7094656546202937\n"
     ]
    }
   ],
   "source": [
    "# Apply VADER: easyJet\n",
    "data['vader_sentiment'] = data['review'].apply(vader_sentiment)\n",
    "\n",
    "# Calculating VADER's evaluation metrics\n",
    "accuracy_vader = accuracy_score(data['real_sentiment'], data['vader_sentiment'])\n",
    "precision_vader = precision_score(data['real_sentiment'], data['vader_sentiment'], average='weighted')\n",
    "recall_vader = recall_score(data['real_sentiment'], data['vader_sentiment'], average='weighted')\n",
    "f1_vader = f1_score(data['real_sentiment'], data['vader_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"VADER Accuracy: {accuracy_vader}\")\n",
    "print(f\"VADER Precision: {precision_vader}\")\n",
    "print(f\"VADER Recall: {recall_vader}\")\n",
    "print(f\"VADER F1 Score: {f1_vader}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e86caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 0.7\n",
      "VADER Precision: 0.6873564143853998\n",
      "VADER Recall: 0.7\n",
      "VADER F1 Score: 0.6706636892397174\n"
     ]
    }
   ],
   "source": [
    "# Apply VADER: British Airways\n",
    "data_2['vader_sentiment'] = data_2['review'].apply(vader_sentiment)\n",
    "\n",
    "# Calculating VADER's evaluation metrics\n",
    "accuracy_vader = accuracy_score(data_2['real_sentiment'], data_2['vader_sentiment'])\n",
    "precision_vader = precision_score(data_2['real_sentiment'], data_2['vader_sentiment'], average='weighted')\n",
    "recall_vader = recall_score(data_2['real_sentiment'], data_2['vader_sentiment'], average='weighted')\n",
    "f1_vader = f1_score(data_2['real_sentiment'], data_2['vader_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"VADER Accuracy: {accuracy_vader}\")\n",
    "print(f\"VADER Precision: {precision_vader}\")\n",
    "print(f\"VADER Recall: {recall_vader}\")\n",
    "print(f\"VADER F1 Score: {f1_vader}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0caff6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541ef231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the IBM Watson NLU service\n",
    "authenticator = IAMAuthenticator('2JQNn0KEKomFqt0Id-cQTkH6z4nHn5KZqTLLUNFaFcuh')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2022-04-07',\n",
    "    authenticator=authenticator)\n",
    "natural_language_understanding.set_service_url('https://api.eu-gb.natural-language-understanding.watson.cloud.ibm.com/instances/d255cf53-8629-4af0-9ecd-560ec0047a3e')\n",
    "\n",
    "# Define IBM Watson NLU sentiment classification function\n",
    "def watson_sentiment(review):\n",
    "    response = natural_language_understanding.analyze(\n",
    "        text=review,\n",
    "        features=Features(sentiment=SentimentOptions())\n",
    "    ).get_result()\n",
    "    sentiment = response['sentiment']['document']['label']\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04aa8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson NLU Accuracy: 0.83\n",
      "Watson NLU Precision: 0.71834375\n",
      "Watson NLU Recall: 0.83\n",
      "Watson NLU F1 Score: 0.7701328753502668\n"
     ]
    }
   ],
   "source": [
    "# Apply IBM Watson NLU: easyJet\n",
    "data['watson_sentiment'] = data['review'].apply(watson_sentiment)\n",
    "\n",
    "# Calculating IBM Watson NLU's evaluation metrics\n",
    "accuracy_watson = accuracy_score(data['real_sentiment'], data['watson_sentiment'])\n",
    "precision_watson = precision_score(data['real_sentiment'], data['watson_sentiment'], average='weighted', zero_division=0)\n",
    "recall_watson = recall_score(data['real_sentiment'], data['watson_sentiment'], average='weighted', zero_division=0)\n",
    "f1_watson = f1_score(data['real_sentiment'], data['watson_sentiment'], average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Watson NLU Accuracy: {accuracy_watson}\")\n",
    "print(f\"Watson NLU Precision: {precision_watson}\")\n",
    "print(f\"Watson NLU Recall: {recall_watson}\")\n",
    "print(f\"Watson NLU F1 Score: {f1_watson}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ae2e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson NLU Accuracy: 0.82\n",
      "Watson NLU Precision: 0.6927028685381194\n",
      "Watson NLU Recall: 0.82\n",
      "Watson NLU F1 Score: 0.7509906592419615\n"
     ]
    }
   ],
   "source": [
    "# Apply IBM Watson NLU: British Airways\n",
    "data_2['watson_sentiment'] = data_2['review'].apply(watson_sentiment)\n",
    "\n",
    "# Calculating IBM Watson NLU's evaluation metrics\n",
    "accuracy_watson = accuracy_score(data_2['real_sentiment'], data_2['watson_sentiment'])\n",
    "precision_watson = precision_score(data_2['real_sentiment'], data_2['watson_sentiment'], average='weighted', zero_division=0)\n",
    "recall_watson = recall_score(data_2['real_sentiment'], data_2['watson_sentiment'], average='weighted', zero_division=0)\n",
    "f1_watson = f1_score(data_2['real_sentiment'], data_2['watson_sentiment'], average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Watson NLU Accuracy: {accuracy_watson}\")\n",
    "print(f\"Watson NLU Precision: {precision_watson}\")\n",
    "print(f\"Watson NLU Recall: {recall_watson}\")\n",
    "print(f\"Watson NLU F1 Score: {f1_watson}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb6558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define TextBlob function\n",
    "def textblob_sentiment(text):\n",
    "    testimonial = TextBlob(text)\n",
    "    polarity = testimonial.sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return 'positive'\n",
    "    elif polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683c4076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Accuracy: 0.615\n",
      "TextBlob Precision: 0.7471906164527666\n",
      "TextBlob Recall: 0.615\n",
      "TextBlob F1 Score: 0.6234941576784798\n"
     ]
    }
   ],
   "source": [
    "#TextBlob: easyJet\n",
    "data['textblob_sentiment'] = data['review'].apply(textblob_sentiment)\n",
    "\n",
    "\n",
    "accuracy_textblob = accuracy_score(data['real_sentiment'], data['textblob_sentiment'])\n",
    "precision_textblob = precision_score(data['real_sentiment'], data['textblob_sentiment'], average='weighted')\n",
    "recall_textblob = recall_score(data['real_sentiment'], data['textblob_sentiment'], average='weighted')\n",
    "f1_textblob = f1_score(data['real_sentiment'], data['textblob_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"TextBlob Accuracy: {accuracy_textblob}\")\n",
    "print(f\"TextBlob Precision: {precision_textblob}\")\n",
    "print(f\"TextBlob Recall: {recall_textblob}\")\n",
    "print(f\"TextBlob F1 Score: {f1_textblob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6bb0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Accuracy: 0.575\n",
      "TextBlob Precision: 0.6460233798195242\n",
      "TextBlob Recall: 0.575\n",
      "TextBlob F1 Score: 0.564662649846231\n"
     ]
    }
   ],
   "source": [
    "#TextBlob\":British Airways\n",
    "data_2['textblob_sentiment'] = data_2['review'].apply(textblob_sentiment)\n",
    "\n",
    "\n",
    "accuracy_textblob = accuracy_score(data_2['real_sentiment'], data_2['textblob_sentiment'])\n",
    "precision_textblob = precision_score(data_2['real_sentiment'], data_2['textblob_sentiment'], average='weighted')\n",
    "recall_textblob = recall_score(data_2['real_sentiment'], data_2['textblob_sentiment'], average='weighted')\n",
    "f1_textblob = f1_score(data_2['real_sentiment'], data_2['textblob_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"TextBlob Accuracy: {accuracy_textblob}\")\n",
    "print(f\"TextBlob Precision: {precision_textblob}\")\n",
    "print(f\"TextBlob Recall: {recall_textblob}\")\n",
    "print(f\"TextBlob F1 Score: {f1_textblob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4b802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define SentiWordNet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def sentiwordnet_sentiment(text):\n",
    "    sentiment = 0.0\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    for word, tag in tagged:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag not in (wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB):\n",
    "            continue\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "        synsets = wordnet.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "    return 'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194bb352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiWordNet Accuracy: 0.495\n",
      "SentiWordNet Precision: 0.6513214246695073\n",
      "SentiWordNet Recall: 0.495\n",
      "SentiWordNet F1 Score: 0.5133528138528138\n"
     ]
    }
   ],
   "source": [
    "#SentiWordNet: easyJet\n",
    "data['sentiwordnet_sentiment'] = data['review'].apply(sentiwordnet_sentiment)\n",
    "\n",
    "accuracy_sentiwordnet = accuracy_score(data['real_sentiment'], data['sentiwordnet_sentiment'])\n",
    "precision_sentiwordnet = precision_score(data['real_sentiment'], data['sentiwordnet_sentiment'], average='weighted')\n",
    "recall_sentiwordnet = recall_score(data['real_sentiment'], data['sentiwordnet_sentiment'], average='weighted')\n",
    "f1_sentiwordnet = f1_score(data['real_sentiment'], data['sentiwordnet_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"SentiWordNet Accuracy: {accuracy_sentiwordnet}\")\n",
    "print(f\"SentiWordNet Precision: {precision_sentiwordnet}\")\n",
    "print(f\"SentiWordNet Recall: {recall_sentiwordnet}\")\n",
    "print(f\"SentiWordNet F1 Score: {f1_sentiwordnet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d252e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiWordNet Accuracy: 0.52\n",
      "SentiWordNet Precision: 0.6179798622151563\n",
      "SentiWordNet Recall: 0.52\n",
      "SentiWordNet F1 Score: 0.5172602739726028\n"
     ]
    }
   ],
   "source": [
    "#SentiWordNet: British Airways\n",
    "data_2['sentiwordnet_sentiment'] = data_2['review'].apply(sentiwordnet_sentiment)\n",
    "\n",
    "accuracy_sentiwordnet = accuracy_score(data_2['real_sentiment'], data_2['sentiwordnet_sentiment'])\n",
    "precision_sentiwordnet = precision_score(data_2['real_sentiment'], data_2['sentiwordnet_sentiment'], average='weighted')\n",
    "recall_sentiwordnet = recall_score(data_2['real_sentiment'], data_2['sentiwordnet_sentiment'], average='weighted')\n",
    "f1_sentiwordnet = f1_score(data_2['real_sentiment'], data_2['sentiwordnet_sentiment'], average='weighted')\n",
    "\n",
    "print(f\"SentiWordNet Accuracy: {accuracy_sentiwordnet}\")\n",
    "print(f\"SentiWordNet Precision: {precision_sentiwordnet}\")\n",
    "print(f\"SentiWordNet Recall: {recall_sentiwordnet}\")\n",
    "print(f\"SentiWordNet F1 Score: {f1_sentiwordnet}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
